{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Week 2 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Scraping permit data\n",
    "Here's the code that we saw in the video lecture that queries the City of Seattle permit website, gets a dataframe of permits (including the URL), and then digs down further into that permit-specific URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89222500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the permit data from the API\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://data.seattle.gov/resource/ht3q-kdvx.json' # copied and pasted from the webpage\n",
    "r = requests.get(url)\n",
    "df = pd.DataFrame(json.loads(r.text))\n",
    "\n",
    "df = df.head(5) # get the first 5 rows, so we don't overload the city's website.\n",
    "\n",
    "# get an example link\n",
    "permiturl = df.loc[0,'link']['url']\n",
    "print(permiturl)\n",
    "\n",
    "# request that page and get the soup object\n",
    "r = requests.get(permiturl)\n",
    "soup = BeautifulSoup(r.text)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59022053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we wrote this code to extract the project description \n",
    "links = soup.find_all('td')\n",
    "for link in links:\n",
    "    if 'Project Description' in link.text: \n",
    "        sublinks = link.find_all('td')\n",
    "        description = sublinks[1].text\n",
    "        # once we find a description, we exit\n",
    "        break\n",
    "    \n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d730d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> If you look at the example, there is a <strong>Legal Description</strong> section. Extract that to a variable and print it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we wrote this code to extract the project description \n",
    "links = soup.find_all('tr')\n",
    "for link in links:\n",
    "    if 'Legal Description' in link.text: \n",
    "        sublinks = link.find_all('td')\n",
    "        description = sublinks[5].text\n",
    "        # once we find a description, we exit\n",
    "        break\n",
    "    \n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fefc9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Now turn that into a function that you can apply to each row of your dataframe. Add a new column, <strong>legal_description</strong>, to your dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we wrote this code to extract the project description \n",
    "def get_legal(urldict):\n",
    "    permiturl = urldict['url']\n",
    "\n",
    "    # request that page and get the soup object\n",
    "    r = requests.get(permiturl)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    print(soup.prettify())\n",
    "    links = soup.find_all('tr')\n",
    "    for link in links:\n",
    "        if 'Legal Description' in link.text: \n",
    "            sublinks = link.find_all('td')\n",
    "            description = sublinks[5].text\n",
    "            # once we find a description, we exit\n",
    "            return sublinks[5]\n",
    "\n",
    "sl = get_legal(df.loc[0,'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774e339",
   "metadata": {},
   "source": [
    "### Fixing errors\n",
    "We'll do more scraping in just a moment. But first, let's do some examples of how to interpret an error message, and fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7c600",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Each of the cells below will generate an error. Look at the error message and see if you can figure out how to fix it. (Don't Google it until you try to figure it out based on the error message.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dad38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the housingunitsremoved and housingunitsadded give useful information\n",
    "# let's create a new column with netunits\n",
    "df['netunits'] = df.housingunitsadded - df.housingunitsremoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the address of the first row\n",
    "print('Address of first row is {}. Permit type is {}'.format(df.iloc[0].originaladdress1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the number of housing units to integers\n",
    "# and then summarize\n",
    "\n",
    "df['unitsadded_numeric'] = df.housingunitsadded.astype(int)\n",
    "df.unitsadded_numeric.describe("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e25862",
   "metadata": {},
   "source": [
    "### Scraping craigslist\n",
    "\n",
    "In the lecture, we saw how to scrape the main page (the list of posts).\n",
    "\n",
    "What if you want to get more information about (say) a particular apartment?\n",
    "\n",
    "Here's the code from the lecture that gets a dataframe of the first 120 posts. Notice that there is a `url` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://losangeles.craigslist.org/search/lac/hhh'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.content)\n",
    "posts = soup.find_all('li', class_= 'result-row')\n",
    "\n",
    "postList = []\n",
    "\n",
    "for post in posts:\n",
    "    result_price = post.find('span', class_= 'result-price')\n",
    "    if result_price is None:\n",
    "        price = None\n",
    "    else:\n",
    "        price = result_price.text\n",
    "    \n",
    "    resulthood = post.find('span', class_= 'result-hood')\n",
    "    if resulthood is None:\n",
    "        neighborhood = None\n",
    "    else:\n",
    "        neighborhood = resulthood.text \n",
    "        \n",
    "    # we can also have our if..else statements as a one-liner\n",
    "    # this is identical to the above\n",
    "    neighborhood = None if resulthood is None else resulthood.text\n",
    "\n",
    "    housing = post.find('span', class_= 'housing')\n",
    "    housingsize = None if housing is None else housing.text\n",
    "        \n",
    "    # these two fields seem to be always present, so no need to check for None\n",
    "    title = post.find('a', class_= 'result-title').text\n",
    "    url = post.find('a', class_= 'result-title')['href']\n",
    "\n",
    "    # now put them in the dictionary, and append to our list\n",
    "    postList.append({'price': price, 'neighborhood':neighborhood, \n",
    "                     'housingsize':housingsize, 'title':title, 'url':url})\n",
    "\n",
    "df = pd.DataFrame(postList)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3f6d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> For the first url in your dataframe, use requests to get the content of the post. (No need to create a soup object yet.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8705a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# put the output of the request in a variable called r\n",
    "# so you can access the content like this\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e3794",
   "metadata": {},
   "source": [
    "Now let's extract more information from the page. We have a couple of strategies here. First, we could skip trying to parse the page with `BeautifulSoup`, and just see if particular bits of text are present.\n",
    "\n",
    "For example, what transportation modes does the post emphasize? Do they mention Section 8 vouchers? Some of this might be exploratoryâ€”we can see what type of language is included, and then parse in a more structured way (e.g. distinguishing between \"No Section 8\" and \"Section 8 welcome\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bdf82",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Write a function that will return True if Section 8 is mentioned, otherwise False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb944b5",
   "metadata": {},
   "source": [
    "*Hint*: the `in` operator is a simple way to do this. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'plan' in 'urban planning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f97024",
   "metadata": {},
   "outputs": [],
   "source": [
    "'plan' in 'Urban Planning' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806158ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to return Section 8 information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bacd1",
   "metadata": {},
   "source": [
    "Most of the post is free-form text. So there's not going to be much value added by `BeautifulSoup`.\n",
    "\n",
    "The exceptions are (i) parking, and (ii) the geographic coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30412ae2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Write a function that will return True if the apartment has no parking, and also returns the lat/lon of the apartment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a497c9",
   "metadata": {},
   "source": [
    "*Hint*: First, create a `soup` object. Then, look and see what tag and class encloses this information. Then, you can experiment with `find` and `find_all` with this tag and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7baf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf1b0e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Apply this function to your dataframe, and create new columns for parking, lat, and lon.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38778d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>What you should have learned</h3>\n",
    "<ul>\n",
    "  <li>Gain confidence in experimenting with code - exploring different objects, writing functions, and so on</li>\n",
    "  <li>Learn how to extract information from a scraped webpage - how to do the detective work.</li>\n",
    "  <li>Gain confidence in debugging errors.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
