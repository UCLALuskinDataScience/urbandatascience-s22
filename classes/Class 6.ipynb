{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Week 6 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class. We'll do an extension of the random forests classifier, looking at a continuous variable. Then, we'll do some cluster analysis.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Classification: NYC evictions\n",
    "We'll look at the factors that are associated with evictions in New York City. Perhaps a machine learning model can identify the types of places that are vulnerable to eviction, and target renter assistance programs more effectively?\n",
    "\n",
    "#### Loading in the data\n",
    "\n",
    "Let's start by loading in the [eviction dataset](https://data.cityofnewyork.us/City-Government/Evictions/6z8x-wfk4) via Socrata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30faed6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Import the data from Socrata via the API into a pandas DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b86bd",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Look back at Week 1 if you need a refresher on using Socrata\n",
    "- There are about 70,000 rows in the dataset. So remember to add `?$limit=100000` to the end of the URL that you pass to `requests.get()`. Otherwise, you'll just get the first 1,000 rows. (The limit can be anything comfortably above 70000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549f5a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Convert your dataframe to a GeoDataFrame, using the latitude and longitude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5657ee",
   "metadata": {},
   "source": [
    "Now let's import some census data. We could use `cenpy` or the Census Bureau API. But to keep things simple so that we can focus on the spatial joins and the machine learning, I downloaded the block group-level 2019 ACS data for New York from the [Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-data.html). To save space, I clipped it to the 5 NYC counties.\n",
    "\n",
    "It's in your repository, and we can load it in as follows. If you aren't familiar with a GeoPackage (GPKG) format, think of it as a \"new and improved shapefile.\" [Here's a good overview.](https://towardsdatascience.com/why-you-need-to-use-geopackage-files-instead-of-shapefile-or-geojson-7cb24fe56416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = gpd.read_file('data/nyc_bgs.gpkg')\n",
    "bgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295e3d",
   "metadata": {},
   "source": [
    "Note that the variables aren't particularly carefully selected - I just threw in many of the demographic and housing variables. \n",
    "\n",
    "Nor are the variable names particularly informative, but the full names are in a file in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86627295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note it is tab-sepated, not comma separated\n",
    "# so we use the sep='\\t' argument\n",
    "\n",
    "col_names = pd.read_csv('data/BG_METADATA_2019.txt', sep='\\t', index_col='Short_Name')\n",
    "col_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ea2c7",
   "metadata": {},
   "source": [
    "So you can see the definition of the column like this. (I don't recommend renaming the `bg` column names, because the full names are so long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names.loc['B01001e1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da707b5",
   "metadata": {},
   "source": [
    "#### Spatial join\n",
    "Now let's do the spatial join. Again, let's follow our three step process.\n",
    "\n",
    "1. Use a spatial join to add the `GEOID` column to the evictions dataframe. *Hint:* Check your projections.\n",
    "2. Group by `GEOID` to get a count of evictions per block group. If you have a `Series`, give it a name - maybe `n_evictions`\n",
    "3. Join those counts back - a tabular join based on the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd0b18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Add a count of evictions per census block group to your <strong>bgs</strong> GeoDataFrame, using the 3-step process above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc447f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89523f4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Do a quick-and-dirty map of the number of evictions. This will help identify any data holes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b5b4f",
   "metadata": {},
   "source": [
    "#### Random forests regressor\n",
    "Now we have our data set. Let's estimate a random forests model.\n",
    "\n",
    "In contrast to the previous examples, we are trying to predict a continuous variable - the number of evictions. So our classifier isn't appropriate. \n",
    "\n",
    "However, there is a similar model: the [random forest regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor). It works almost identically to the classifier. The main difference from a user perspective is assessing model performance - a confusion matrix doesn't work here.\n",
    "\n",
    "You'll need to follow the following steps:\n",
    "- choose your x variables. (Your y variable will be `n_evictions`)\n",
    "- Drop Null values if needed\n",
    "- split your dataset into training and testing portions\n",
    "- estimate (fit) the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24327cee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Estimate a random forest regressor model to predict the number of evictions per census tract.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192468ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5483eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Assess the fit of your model.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded99af",
   "metadata": {},
   "source": [
    "Remember, the confusion matrix and accuracy scores don't apply here. Some ideas for continuous variables are [here](https://stackoverflow.com/questions/50789508/random-forest-regression-how-do-i-analyse-its-performance-python-sklearn). You could also plot actual vs predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779701e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5e2a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Which variables are most important in your predictions? Plot the forest importances.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d83e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518387dd",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "We'll now look at some k-means cluster analysis. The question: are there particular patterns of cruising for parking? You can see [my version of the analysis here](https://findingspress.org/article/28061-the-shape-of-cruising), joint with Robert Hampshire and Rachel Weinberger.\n",
    "\n",
    "The data file that replicate the analysis is in your data folder. There is one row for each cruising trip (derived from the final portion of a GPS trace, once a driver is assumed to start looking for parking.)\n",
    "\n",
    "You can load the data as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cruisingDf = pd.read_csv('data/cruising_shapes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09baf9bb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Replicate the analysis in Millard-Ball, Hampshire and Weinberger (2021). First, add each cluster label to the dataframe.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79648a",
   "metadata": {},
   "source": [
    "In the paper, we used 5 clusters and the following columns: `'matchdist', 'frc_repeat', 'n_crossings', 'convexhull_ratio', 'frc_right', 'frc_left', 'frc_uturn', 'frc_straight', 'n_turns'`\n",
    "\n",
    "* `matchdist` is path length (technically, the map-matched distance)\n",
    "* `frc_repeat` is the fraction of repeated blocks (a driver drives on them more than once while cruising for parking)\n",
    "* `n_crossings` is the number of times that the driver crosses over their path\n",
    "* `convexhull_ratio` is a measure of the compactness of the search area\n",
    "* `frc_right`, `frc_left`, `frc_uturn` and `frc_straight` are the fraction of times that the driver turns right or left, makes a U-turn, or continues straight at an intersection\n",
    "* `n_turns` is the number of turns in the cruising trace\n",
    "\n",
    "You'll need to:\n",
    "* standardize the variables\n",
    "* drop Null values\n",
    "* run the k-means algorithm\n",
    "* add the cluster labels back to your dataframe\n",
    "\n",
    "How many observations do you get in each cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b299e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Create a radar plot of your clusters.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132fa03",
   "metadata": {},
   "source": [
    "Here's the function to create the radar chart, which we used in the video lecture.\n",
    "\n",
    "It takes two arguments: the `kmeans` object created by `KMeans`, and your standardized dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell defines the radar_plot() function that we used in lecture\n",
    "# no need to change anything here. Add your code in the cell below\n",
    "\n",
    "# code from https://matplotlib.org/stable/gallery/specialty_plots/radar_chart.html\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "\n",
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle', 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        # use 1 line segment to connect specified points\n",
    "        RESOLUTION = 1\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                # unit_regular_polygon gives a polygon of radius 1 centered at\n",
    "                # (0, 0) but we want a polygon of radius 0.5 centered at (0.5,\n",
    "                # 0.5) in axes coordinates.\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta\n",
    "\n",
    "def radar_plot(kmeans, df_scaled):\n",
    "    N  = kmeans.cluster_centers_.shape[1]  # number of columns / variables\n",
    "    k = kmeans.n_clusters\n",
    "    theta = radar_factory(N, frame='polygon')\n",
    "    data = kmeans.cluster_centers_.T\n",
    "    spoke_labels = [col for col in df_scaled.columns if col!='cluster_id']\n",
    "    fig, ax = plt.subplots(figsize=(9, 9),\n",
    "                                subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)\n",
    "\n",
    "    ax.plot(theta, data) #, color=color)\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    # add legend relative to top-left plot\n",
    "    labels = ['Cluster {}'.format(kk) for kk in range(k)]\n",
    "    ax.legend(labels, loc=(0.9, .95),\n",
    "                                labelspacing=0.1, fontsize='small')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069be75",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Experiment with different values of k (number of clusters), and using different columns.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1b7fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> The dataframe comes with x and y coordinates. Use them to identify any spatial clusters of cruising trips in San Francisco.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae74ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>What you should have learned</h3>\n",
    "<ul>\n",
    "  <li>Get more practice with spatial joins and Socrata.</li>\n",
    "  <li>Learn how to estimate a random forests model for continuous data.</li>\n",
    "  <li>Get more practice with standardizing data.</li>\n",
    "  <li>Learn how to estimate a k-means cluster analysis.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d2e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
