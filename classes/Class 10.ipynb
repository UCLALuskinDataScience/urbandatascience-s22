{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Week 10 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class. \n",
    "\n",
    "We'll revisit our analysis of ADUs, and try and speed things up and reduce memory usage.\n",
    "\n",
    "Then, we'll have some practice with SQL.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Optimizing data types and parsing csv files\n",
    "Let's revist the ADU data that we saw in Lecture 12 (classification). There are two csv files that we read in – one with the permit data, and one with the parcel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4133f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15741 entries, 0 to 15740\n",
      "Data columns (total 4 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Assessor Book                  15741 non-null  float64\n",
      " 1   Assessor Page                  15741 non-null  float64\n",
      " 2   Assessor Parcel                15741 non-null  object \n",
      " 3   # of Accessory Dwelling Units  15741 non-null  float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 492.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "permits = pd.read_csv('../lectures/data/ADU_permits.csv')  # this file should be in your GitHub folder\n",
    "permits.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e096fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 789182 entries, 0 to 789181\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   APN                789182 non-null  object \n",
      " 1   UseType            789140 non-null  object \n",
      " 2   UseDescription     789140 non-null  object \n",
      " 3   YearBuilt1         778940 non-null  float64\n",
      " 4   Units1             778940 non-null  float64\n",
      " 5   Bedrooms1          778940 non-null  float64\n",
      " 6   Bathrooms1         778940 non-null  float64\n",
      " 7   SQFTmain1          778940 non-null  float64\n",
      " 8   Roll_LandValue     782704 non-null  float64\n",
      " 9   Roll_ImpValue      782704 non-null  float64\n",
      " 10  Roll_LandBaseYear  789182 non-null  int64  \n",
      " 11  Roll_ImpBaseYear   789182 non-null  int64  \n",
      " 12  CENTER_LAT         789182 non-null  float64\n",
      " 13  CENTER_LON         789182 non-null  float64\n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 84.3+ MB\n"
     ]
    }
   ],
   "source": [
    "parcels = pd.read_csv('../lectures/data/parcels.csv')\n",
    "parcels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f995697",
   "metadata": {},
   "source": [
    "For me, the permits data takes 492KB of memory. The parcels data uses 84MB. Imagine that you had a much bigger data file (perhaps more counties, or perhaps more columns). How can you reduce the memory requirements of these dataframes?\n",
    "\n",
    "*Hint*: I didn't mention this in the lecture, but pandas has a new \"nullable integer\" datatype which can take missing values (NaNs).\n",
    "\n",
    "To take advantage of this, use `Int16`, `Int32`, etc. rather than `int16`, `int32`, etc. The capital I is the nullable integer datatype; the lower-case i is the numpy datatype. [See here for a detailed explanation.](https://pandas.pydata.org/docs/user_guide/integer_na.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89523f4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Reduce the memory usage of each dataframe as much as you can.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39662ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea52f5",
   "metadata": {},
   "source": [
    "Now, imagine that the dataframes wouldn't even load into memory in the first place?\n",
    "\n",
    "Also imagine that you don't need the `Bathrooms1` column.\n",
    "\n",
    "Use additional arguments to `pd.read_csv()` and the datatypes you used in the answer above to load in the dataframes again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b920d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Load the dataframes from disk in the most memory-efficient way possible.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b5b4f",
   "metadata": {},
   "source": [
    "### Speeding up joins\n",
    "\n",
    "Now let's try and join them together in an efficient way.\n",
    "\n",
    "Remember `%timeit` (for a line of code) and `%%timeit` (for a cell) will tell you how long your code takes to run.\n",
    "\n",
    "Before we join, we need to drop the rows with no parcel number, and create a concatenated column for the APN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf6f7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assessor Book</th>\n",
       "      <th>Assessor Page</th>\n",
       "      <th>Assessor Parcel</th>\n",
       "      <th># of Accessory Dwelling Units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-004-010</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-004-011</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-006-011</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-009-007</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-010-020</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Assessor Book  Assessor Page Assessor Parcel  \\\n",
       "APN                                                          \n",
       "2004-004-010         2004.0            4.0             010   \n",
       "2004-004-011         2004.0            4.0             011   \n",
       "2004-006-011         2004.0            6.0             011   \n",
       "2004-009-007         2004.0            9.0             007   \n",
       "2004-010-020         2004.0           10.0             020   \n",
       "\n",
       "              # of Accessory Dwelling Units  \n",
       "APN                                          \n",
       "2004-004-010                            1.0  \n",
       "2004-004-011                            1.0  \n",
       "2004-006-011                            1.0  \n",
       "2004-009-007                            1.0  \n",
       "2004-010-020                            1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permits = permits[permits['Assessor Parcel']!='***']\n",
    "permits['APN'] = (permits['Assessor Book'].astype(int).astype(str).str.zfill(4) + '-' \n",
    "                   + permits['Assessor Page'].astype(int).astype(str).str.zfill(3) + '-'\n",
    "                   + permits['Assessor Parcel'].astype(int).astype(str).str.zfill(3))\n",
    "#drop the duplicates (take the first)\n",
    "permits = permits.groupby('APN').first()\n",
    "parcels = parcels.groupby('APN').first()\n",
    "\n",
    "permits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f9390",
   "metadata": {},
   "source": [
    "This is how we joined the parcels in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4598912",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDf = parcels.join(permits, how='left') # left is the default so we could omit that argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff9249",
   "metadata": {},
   "source": [
    "How long does that take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d125ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.5 ms ± 154 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit joinedDf = parcels.join(permits, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43893f",
   "metadata": {},
   "source": [
    "What if we use `pd.merge()` on a column, rather than the index? \n",
    "\n",
    "Let's first reset the indexes, so that `APN` becomes a regular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ea077",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels.reset_index(inplace=True)\n",
    "permits.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24327cee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> How long does it take to merge using the columns?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1924fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c9043",
   "metadata": {},
   "source": [
    "If you are curious, indexes are faster because they are [stored as hashes](https://stackoverflow.com/questions/27238066/what-is-the-point-of-indexing-in-pandas).\n",
    "\n",
    "Before we move on, let's create the `has_adu` column as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0736fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDf['has_adu'] = joinedDf['# of Accessory Dwelling Units']>=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e0b78",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "Finally, let's do some simple SQL queries on the joined dataframe.\n",
    "\n",
    "Implement the following queries as SQL, using `pandasql`.\n",
    "\n",
    "1. What's the total land value of all the parcels? (The column `Roll_LandValue`.)\n",
    "\n",
    "2. How many parcels have ADUs? \n",
    "\n",
    "3. What's the average area of the building size (`SQFTmain1`), with and without an ADU? (Hint: use `GROUP BY`.)\n",
    "\n",
    "4. Same as above, but for residential parcels only (`UseType='Residential'`)\n",
    "\n",
    "Compare your results to a typical `pandas` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>You should now be able to:</h3>\n",
    "<ul>\n",
    "  <li>Deal with larger datasets on a standard laptop computer</li>\n",
    "  <li>Profile your code to identify bottlenecks</li>\n",
    "  <li>Write simple SQL queries</li>\n",
    "  <li>Go forth and do data science!</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d2e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
