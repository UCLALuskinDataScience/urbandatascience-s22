{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5244ba7",
   "metadata": {},
   "source": [
    "# Databases and SQL\n",
    "## Lecture objectives\n",
    "\n",
    "1. Understand when and why you would want to use a database, rather than `pandas`\n",
    "2. Learn how to set up a PostgreSQL and PostGIS database\n",
    "3. Learn some basic SQL queries\n",
    "4. Introduce how to integrate a database with Python and QGIS\n",
    "\n",
    "Today's course will be mostly a taster. We won't do much on coding in SQL. Rather, I want to give you enough background so that you'll know when you should go further, and where to start.\n",
    "\n",
    "One takeway: you should never need to pay money for ArcGIS. The open-source substitutes are fabulous! (But as long as most public agencies continue to think otherwise, ArcGIS is still an important skill for planners.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5131626",
   "metadata": {},
   "source": [
    "## Why use a database\n",
    "In most cases, Python in general, and `pandas`/`geopandas` in particular, will do an excellent job for your data science workflow. But sometimes, they might not be the best option. Here are some situations when you might want to consider a database.\n",
    "* Your dataset won't fit in memory\n",
    "* Multiple users need access at the same time\n",
    "* You need to validate and maintain the integrity of the data through access controls and transactions (a transaction means that if the computer crashes halfway through, your data integrity is unaffected)\n",
    "\n",
    "Many planning agencies have databases already hosted on the agency's server, for example to store land-use permits or GIS files. Some of these might be spatial databases, e.g. with ESRI's ArcGIS suite. You might need to query these as part of your work.\n",
    "\n",
    "You can also set up your own database, even on a laptop. External hard drives are pretty cheap. Of course, if you want someone else to access it, an always-on computer with a stable internet connection is needed. But this could even be an old computer that you keep in the corner of the office or lab.\n",
    "\n",
    "**Key takeaway:** Data that needs to be preserved and maintained, whether permit issuance, rider surveys, or asset inventories such as bus stops, shouldn't be an Excel file on someone's computer. What happens if they retire or their computer gets stolen? Or someone inadvertently \"corrects\" the data and introduces errors? Or different users have different versions of the Excel file on their computers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc04b8",
   "metadata": {},
   "source": [
    "## How to set up a database\n",
    "I highly recommend PostgreSQL (Postgres for short). It's free, open-source, and cross-platform (runs on Windows, Mac, and Linux.) It is well supported and updated, and has incredible spatial analysis capabilities through the [PostGIS](http://postgis.net) extension.\n",
    "\n",
    "Most databases use the same language — SQL, which stands for Structured Query Language. So if you learn Postgres, you should be able to use pretty much any alternative with minimal hassle.\n",
    "\n",
    "Installing Postgres is simple. We won't need to do it for this class. But if you feel inclined to experiment, [the PostGIS site provides a list of downloadable versions](http://postgis.net/install/). For Mac, I recommend postgres.app to get started, as it works just like any Mac app, and the Homebrew version for more advanced users.\n",
    "\n",
    "You don't need any sort of fancy computer to download and run Postgres. If you have large datasets or intensive computations, almost any cloud provider (e.g. AWS) lets you run Postgres. But for most purposes, a standard laptop or desktop computer will work well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a5ccf",
   "metadata": {},
   "source": [
    "## Database structure and access\n",
    "Postgres organizes your data into:\n",
    "* Databases. For example, I usually have one database per research project.\n",
    "* Schemas. These are like directories on your computer, to organize your tables. For example, you might have schemas for `inputdata`, `working`, and `output`.\n",
    "* Tables. Each Postgres table is like a `(geo)pandas` `DataFrame`.\n",
    "\n",
    "How do you access the data? Here are some options:\n",
    "* The graphical interface `pgAdmin 4`, which runs in a web browser\n",
    "* The command line (`psql`)\n",
    "* If you have spatial data, [QGIS](https://qgis.org/en/site/), an open-source alternative to ArcMap\n",
    "* And of course...Python. `pandas` can read and write database tables with the `read_sql_query` and `to_sql` functions. For more flexibility, the `psycopg2` (soon-to-be `psycopg3`) library provides more power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584681a9",
   "metadata": {},
   "source": [
    "## Basic SQL\n",
    "Even if you don't set up your own database, it can be useful to know how to query a database using SQL. The intuition is pretty similar to `pandas` — particularly with joins and `groupby` functions.\n",
    "\n",
    "Here, we will walk through some practical examples. But rather than querying a database using SQL, we'll query a `pandas` dataframe using SQL, using `pandasql`. \n",
    "\n",
    "We'll use the same Ventura County collisions data from a couple of weeks ago. [Here's a refresher on the data structure.](https://tims.berkeley.edu/help/SWITRS.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be387a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "collisionDf = pd.read_csv('data/Collisions.csv')\n",
    "partiesDf   = pd.read_csv('data/Parties.csv')\n",
    "victimsDf   = pd.read_csv('data/Victims.csv')\n",
    "\n",
    "# let's convert the columns to lower case to make them easier to read\n",
    "# also, in Postgres, all column names are lower case\n",
    "for df in [collisionDf, partiesDf, victimsDf]:\n",
    "    df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisionDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515db46",
   "metadata": {},
   "source": [
    "### SELECT...FROM\n",
    "The simplest SQL queries take this form:\n",
    "\n",
    "`SELECT column1, column2...FROM tablename;`\n",
    "\n",
    "Note the `;` at the end of each query.\n",
    "\n",
    "For example, suppose we want to get two columns from `collisionDf`: `collision_date` and `officer_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('SELECT collision_date, officer_id FROM collisionDf;').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82fe64",
   "metadata": {},
   "source": [
    "The equivalent in `pandas`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07324ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisionDf[['collision_date', 'officer_id']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2f465",
   "metadata": {},
   "source": [
    "### WHERE\n",
    "What if we only want to get a subset of rows? Use `WHERE`.\n",
    "\n",
    "`SELECT column1, column2...FROM tablename WHERE condition;`\n",
    "\n",
    "For example, suppose we want to get the two columns where a pedestrian is involved. From the documentation, this is any value except `A` in the `ped_action` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ace0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('SELECT collision_date, officer_id FROM collisionDf WHERE ped_action!=\"A\";').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6436059",
   "metadata": {},
   "source": [
    "The equivalent in `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21376e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisionDf[collisionDf.ped_action!='A'][['collision_date', 'officer_id']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b085b55",
   "metadata": {},
   "source": [
    "### Other useful queries\n",
    "* Rather than a column name, `*` gives you all columns\n",
    "* `DISTINCT` gives unique values\n",
    "* `LIMIT` limits the number of rows returned (e.g. `LIMIT 10`)\n",
    "* `COUNT(*)` gives the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3de9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('SELECT DISTINCT officer_id FROM collisionDf;').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603da193",
   "metadata": {},
   "source": [
    "In `pandas`, I'd probably use `unique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisionDf.officer_id.unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('SELECT DISTINCT officer_id FROM collisionDf LIMIT 2;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('SELECT COUNT(*) FROM collisionDf WHERE officer_id=3386;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ebf69a",
   "metadata": {},
   "source": [
    "### GROUP BY\n",
    "\n",
    "`GROUP BY` works the same way, at least conceptually as in `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('SELECT juris, COUNT(*) AS n FROM collisionDf GROUP BY juris;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c52851",
   "metadata": {},
   "source": [
    "In `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b671c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisionDf.groupby('juris').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072250a",
   "metadata": {},
   "source": [
    "### JOINS\n",
    "Finally, we can join tables together. Normally, to save disk space, we'd do this on the fly, rather than creating new joined tables.\n",
    "\n",
    "The join concepts, such as left joins, inner joins, 1:1 joins, are the same as in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the ''' allows a string to go over multiple lines, for readability\n",
    "sqldf('''SELECT *\n",
    "         FROM collisionDf \n",
    "         LEFT JOIN partiesDf USING (case_id);''').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf3353",
   "metadata": {},
   "source": [
    "### Spatial operations\n",
    "PostGIS supports all the spatial operations that are in `geopandas`, and many more. For example:\n",
    "\n",
    "`SELECT * FROM parcels, cities WHERE ST_Intersects(parcels.geom, cities.geom);`\n",
    "\n",
    "does a spatial join on the two tables, using the `geom` (geometry) column.\n",
    "\n",
    "Unfortunately they aren't implemented in `pandasql`, so we can't practice them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ef2d2",
   "metadata": {},
   "source": [
    "## A Python-based stack\n",
    "We could have done all of these operations just as easily in basic `pandas`. Normally, there's no need to use `pandasql`. The point here is to demonstrate the SQL syntax, so that you can query other databases. \n",
    "\n",
    "A broader point is that Python is ideally suited to gluing together different operations. Technical and scientific software has Python \"bindings\" — you can access their functionality from within Python. For example:\n",
    "* Postgres and other databases, via `psycopg2`\n",
    "* Statistical software: Stata and R (use the `rpy2` library), or Stan (use `pystan`) if you are a Bayesian\n",
    "* GIS software: QGIS, ArcGIS\n",
    "* System-level functions like copying files and opening a web browser\n",
    "\n",
    "## For more information\n",
    "I highly recommend PostGIS in Action as an excellent introduction to PostGIS, with some basic background on PostgreSQL. [The UCLA library has a hard copy and ebook.](https://ucla.on.worldcat.org/oclc/910352485) For PostgreSQL and SQL more generally, there are many free online courses, [such as this one at UC Davis](https://www.coursera.org/specializations/learn-sql-basics-data-science)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c0b71",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Databases are more complicated to work with than pandas dataframes. But they are a good solution if you have a lot of data, more than one concurrent user, or requirements for data validation and integrity.</li>\n",
    "  <li>SQL uses different syntax, but the conceptual framework is similar to querying a pandas dataframe.</li>\n",
    "  <li>Python can be used as a glue that holds your data collection and analysis pipeline together.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6eaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
