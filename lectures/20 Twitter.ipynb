{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7853aaf0",
   "metadata": {},
   "source": [
    "# Natural language processing part 4:\n",
    "# Obtaining Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e9f6b",
   "metadata": {},
   "source": [
    "## Lecture objectives\n",
    "* Learn how to scrape Twitter data using their API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505057a",
   "metadata": {},
   "source": [
    "We reviewed topic modeling in the previous lecture. Here and in the next lecture, we'll focus on another common Natural Language Processing tool: sentiment analysis. In short, sentiment analysis tries to understand whether a snippet of text (e.g. a tweet, a review, or a sentence from an article) is positive, negative, or neutral.\n",
    "\n",
    "We'll apply sentiment analysis to some Twitter data on public transportation.\n",
    "\n",
    "If you want to access the Twitter data yourself, you'll need to [sign up for a Twitter developer account](https://developer.twitter.com/en/docs/developer-portal/overview), which will give you an API key. The default access is 7 days, but the academic research product gives you access to the full archive as well as providing geographic filters (e.g. to search for tweets within a bounding box).\n",
    "\n",
    "However, you can also just watch this lecture, and resume in interactive mode in the subsequent lecture.\n",
    "\n",
    "For a thorough treatment of obtaining, analyzing, and interpreting Twitter data, check out [*Twitter as Data*](https://www.cambridge.org/core/elements/twitter-as-data/27B3DE20C22E12E162BFB173C5EB2592) by Prof. Zachary Steinert-Threlkeld here in the Luskin School of Public Affairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d434b4",
   "metadata": {},
   "source": [
    "## Using the Twitter API\n",
    "The `tweepy` library provides easy access to Twitter data, once you [register for an API key](https://developer.twitter.com/en/docs/twitter-api/getting-started/getting-access-to-the-twitter-api). You can enter your credentials here, or just follow along for the time being.\n",
    "\n",
    "The following code snippets are adapted from *Twitter as Data* or the `tweepy` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c440448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# log in via codes provided by Twitter\n",
    "bearer_token=''\n",
    "client = tweepy.Client(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801173a2",
   "metadata": {},
   "source": [
    "Now we have our `client` object that has several methods.\n",
    "\n",
    "For example, we can search for a keyword and get the text of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "miami = client.search_recent_tweets('transit miami', max_results=10).data\n",
    "miami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ff103",
   "metadata": {},
   "source": [
    "Let's get 100 tweets about transit in three cities. We'll also add `-is:retweet` to the query to exclude retweets. \n",
    "\n",
    "To get more than 100 tweets, we would need to use the `Paginator`, as explained in the [tweepy docs](https://docs.tweepy.org/en/stable/v2_pagination.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "miami   = client.search_recent_tweets('transit miami -is:retweet', max_results=100).data\n",
    "chicago = client.search_recent_tweets('transit chicago -is:retweet', max_results=100).data\n",
    "toronto = client.search_recent_tweets('transit toronto -is:retweet', max_results=100).data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd379c8",
   "metadata": {},
   "source": [
    "We get a list of tweets for each city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(miami)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21adcd",
   "metadata": {},
   "source": [
    "Each element of the list is a tweepy Tweet object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(miami[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4e3ac",
   "metadata": {},
   "source": [
    "What can we do with a tweet? Among the methods that are visible is `text`, which seems useful if we want to get the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c883f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "miami[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "miami[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09fa6db",
   "metadata": {},
   "source": [
    "So let's use a list comprehension to get the text of each tweet, from our list of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "miami   = [tweet.text for tweet in miami]\n",
    "chicago = [tweet.text for tweet in chicago]\n",
    "toronto = [tweet.text for tweet in toronto]\n",
    "miami[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57533d68",
   "metadata": {},
   "source": [
    "Now let's save these tweets to a file. We'll use a pickle, which can save most Python objects in their original format. (We could also have looped over the list of tweets and saved them as text.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f053c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/tweets/miami.pickle', 'wb') as f:\n",
    "    pickle.dump(miami, f)\n",
    "with open('data/tweets/chicago.pickle', 'wb') as f:\n",
    "    pickle.dump(chicago, f)\n",
    "with open('data/tweets/toronto.pickle', 'wb') as f:\n",
    "    pickle.dump(toronto, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c9784",
   "metadata": {},
   "source": [
    "We'll pick up these data in the next lecture and see how to analyze the sentiment of the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce3eca",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Twitter has a powerful API that is relatively easy to use. Twitter also recently released a <a href=\"https://zacharyst.com/2021/01/27/initial-thoughts-on-twitters-academic-accounts/\">new product for academic research</a>.</li>\n",
    "  <li>Twitter is not representative. Whether that matters depends on your particular project and use case.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161b51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
